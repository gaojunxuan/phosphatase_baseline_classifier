{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from gpmodel import gpmodel, gpkernel, chimera_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../inputs/props.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9ad326ac7968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../inputs/props.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../inputs/props.pkl'"
     ]
    }
   ],
   "source": [
    "with open('../inputs/props.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3c9a60fd698f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_X_and_Y(df, all_X, y_column):\n",
    "    not_dropped = ~pd.isnull(df[y_column])\n",
    "    not_dropped = pd.Series(not_dropped, index=df.index)\n",
    "    Ys = df[not_dropped][y_column]\n",
    "    gens = df[not_dropped]['generation']\n",
    "    Ys.index = df[not_dropped]['name']\n",
    "    Xs = all_X.loc[Ys.index]\n",
    "    return Xs, Ys, gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['bin0.1_max_peak', '']\n",
    "lits = [False]\n",
    "mtypes = [gpmodel.GPClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../inputs/X_and_terms.pkl', 'rb') as f:\n",
    "    X_all, terms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/matern52_bin0.1_max_peak_False.pkl\n",
      "[ 20.88092844] [ 76.59353427]\n"
     ]
    }
   ],
   "source": [
    "def train_and_save(df, task, fname, mtype, guesses=None):\n",
    "    X, y, _ = select_X_and_Y(df, X_all, task)\n",
    "    X = X.values\n",
    "    y = y.values  \n",
    "    k = gpkernel.MaternKernel('5/2')\n",
    "    clf = mtype(k, guesses=guesses)\n",
    "    clf.fit(X, y)\n",
    "    clf.dump(fname)\n",
    "    return clf\n",
    "\n",
    "for task, lit, mtype in zip(tasks, lits, mtypes):\n",
    "    fname = '../outputs/matern52_' + task + '_' + str(lit) + '.pkl'\n",
    "    if lit:\n",
    "        clf = train_and_save(df, task, fname, mtype)\n",
    "    else:\n",
    "        clf = train_and_save(df[df['generation'] != 8], task, fname, mtype)\n",
    "    print(fname)\n",
    "    print(clf.hypers, clf.ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['matern52_bin0.1_max_peak_False']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_dict = {True:gpmodel.GPClassifier.load, False: gpmodel.GPRegressor.load}\n",
    "clfs = [cls_dict['bin' in path]('../outputs/' + path) for path in os.listdir('../outputs/') if path != '.DS_Store']\n",
    "fnames = ['.'.join(path.split('.')[:-1]) for path in os.listdir('../outputs/') if path != '.DS_Store']\n",
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in fnames:\n",
    "    with open('../outputs/' + fname + '.txt', 'w') as f:\n",
    "        if 'bin' in fname:\n",
    "            f.write('name,p,mu,var\\n')\n",
    "        else:\n",
    "            f.write('name,mu,var\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "CPU times: user 7h 41min 48s, sys: 15min 36s, total: 7h 57min 24s\n",
      "Wall time: 8h 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('../inputs/all_lit_chimeras_gaps.txt', index_col=0)\n",
    "with open('../inputs/lit_alignment_and_contacts.pkl', 'rb') as f:\n",
    "    ss, contacts = pickle.load(f)\n",
    "amino_acids = ('G', 'A', 'L', 'M', 'F', 'W', 'K', 'Q', 'E', 'S',\n",
    "       'P', 'V', 'I', 'C', 'Y', 'H', 'R', 'N', 'D', 'T', '-')\n",
    "sample_space = [amino_acids for _ in ss]\n",
    "n_splits = 1000\n",
    "n_per = len(df.index) // n_splits\n",
    "inds = [df.index[n * n_per: (n+1) * n_per]\n",
    "        for n in range(n_splits)]\n",
    "inds.append(df.index[n_splits * n_per::])\n",
    "seq_terms = chimera_tools.make_sequence_terms(sample_space)\n",
    "struct_terms = chimera_tools.contacting_terms(sample_space, contacts)\n",
    "all_terms = seq_terms + struct_terms\n",
    "\n",
    "for i, ind in enumerate(inds):\n",
    "    seqs = df.loc[ind]['sequence'].values\n",
    "    if len(seqs) == 0:\n",
    "        continue\n",
    "    if i % (n_splits // 10) == 0:\n",
    "        print(i)\n",
    "    struct_X, _ = chimera_tools.make_contact_X(seqs, sample_space, contacts, contact_terms=struct_terms)\n",
    "    seq_X, _ = chimera_tools.make_sequence_X(seqs,\n",
    "                                             sample_space=sample_space,\n",
    "                                             sequence_terms=seq_terms)\n",
    "    all_X = np.concatenate([seq_X, struct_X], axis=1)\n",
    "    for clf, fname in zip(clfs, fnames):\n",
    "        preds = pd.DataFrame(index=df.loc[ind]['name'].values)\n",
    "        if 'bin' in fname:\n",
    "            pi, mu, var = clf.predict(all_X)\n",
    "            preds['pi'] = pi\n",
    "        else:\n",
    "            mu, var = clf.predict(all_X)\n",
    "        var = np.diag(var)\n",
    "        preds['mu'] = mu\n",
    "        preds['var'] = var\n",
    "        with open('../outputs/' + fname + '.txt', 'a') as f:\n",
    "            preds.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/2GFP_above_parent.pkl\n",
      "[ 0.36061643  0.04737465] [ 117.78582814]\n"
     ]
    }
   ],
   "source": [
    "with open('../inputs/GFP_data.pkl', 'rb') as f:\n",
    "    X, y = pickle.load(f)\n",
    "\n",
    "def train_and_save(X, y, fname, mtype):\n",
    "    k = gpkernel.PolynomialKernel(2)\n",
    "    clf = mtype(k, guesses=None)\n",
    "    clf.fit(X, y)\n",
    "    clf.dump(fname)\n",
    "    return clf\n",
    "\n",
    "task = 'GFP_above_parent'\n",
    "mtype = gpmodel.GPClassifier\n",
    "fname = '../outputs/2' + task + '.pkl'\n",
    "\n",
    "clf = train_and_save(X, y, fname, mtype)\n",
    "print(fname)\n",
    "print(clf.hypers, clf.ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "CPU times: user 1h, sys: 16min 42s, total: 1h 16min 42s\n",
      "Wall time: 1h 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('../outputs/' + fname + '.txt', 'w') as f:\n",
    "    f.write('name,p,mu,var\\n')\n",
    "    \n",
    "df = pd.read_csv('../inputs/all_lit_chimeras_gaps.txt', index_col=0)\n",
    "with open('../inputs/lit_alignment_and_contacts.pkl', 'rb') as f:\n",
    "    ss, contacts = pickle.load(f)\n",
    "amino_acids = ('G', 'A', 'L', 'M', 'F', 'W', 'K', 'Q', 'E', 'S',\n",
    "       'P', 'V', 'I', 'C', 'Y', 'H', 'R', 'N', 'D', 'T', '-')\n",
    "sample_space = [amino_acids for _ in ss]\n",
    "n_splits = 1000\n",
    "n_per = len(df.index) // n_splits\n",
    "inds = [df.index[n * n_per: (n+1) * n_per]\n",
    "        for n in range(n_splits)]\n",
    "inds.append(df.index[n_splits * n_per::])\n",
    "seq_terms = chimera_tools.make_sequence_terms(sample_space)\n",
    "struct_terms = chimera_tools.contacting_terms(sample_space, contacts)\n",
    "all_terms = seq_terms + struct_terms\n",
    "\n",
    "\n",
    "for i, ind in enumerate(inds):\n",
    "    seqs = df.loc[ind]['sequence'].values\n",
    "    if len(seqs) == 0:\n",
    "        continue\n",
    "    if i % (n_splits // 10) == 0:\n",
    "        print(i)\n",
    "    struct_X, _ = chimera_tools.make_contact_X(seqs, sample_space, contacts, contact_terms=struct_terms)\n",
    "    seq_X, _ = chimera_tools.make_sequence_X(seqs,\n",
    "                                             sample_space=sample_space,\n",
    "                                             sequence_terms=seq_terms)\n",
    "    all_X = np.concatenate([seq_X, struct_X], axis=1)\n",
    "    \n",
    "    \n",
    "    preds = pd.DataFrame(index=df.loc[ind]['name'].values)\n",
    "    pi, mu, var = clf.predict(all_X)\n",
    "    preds['pi'] = pi\n",
    "    var = np.diag(var)\n",
    "    preds['mu'] = mu\n",
    "    preds['var'] = var\n",
    "    with open('../outputs/' + fname + '.txt', 'a') as f:\n",
    "        preds.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
